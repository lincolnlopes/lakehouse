{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80473839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carregar o arquivo .env com verificação de erro\n",
    "try:\n",
    "    load_dotenv('C:\\\\Users\\\\Lincoln\\\\source\\\\repos\\\\lakehouse\\\\delta\\\\.env')\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o arquivo .env: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Definir todas as variáveis necessárias com verificação\n",
    "required_vars = [\n",
    "    \"AZURE_ACCOUNT_NAME\",\n",
    "    \"AZURE_CLIENT_ID\",\n",
    "    \"AZURE_ACCOUNT_KEY\",\n",
    "    \"AZURE_ACCOUNT_SECRET\"\n",
    "]\n",
    "\n",
    "# Verificar se todas as variáveis estão definidas\n",
    "missing_vars = []\n",
    "for var in required_vars:\n",
    "    value = os.getenv(var)\n",
    "    if value is None:\n",
    "        # Defina valores padrão para desenvolvimento/teste\n",
    "        os.environ[var] = f\"dummy-{var.lower()}\"\n",
    "        print(f\"Variável de ambiente '{var}' não encontrada. Usando valor padrão para desenvolvimento.\")\n",
    "\n",
    "# Criar o dicionário storage_options apenas após verificar todas as variáveis\n",
    "storage_options = {\n",
    "    \"AZURE_STORAGE_ACCOUNT_NAME\": os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\"),\n",
    "    \"AZURE_STORAGE_ACCESS_KEY\": os.getenv(\"AZURE_STORAGE_ACCESS_KEY\"),\n",
    "    \"AZURE_STORAGE_CLIENT_ID\": os.getenv(\"AZURE_STORAGE_CLIENT_ID\"),\n",
    "    \"AZURE_STORAGE_CLIENT_SECRET\": os.getenv(\"AZURE_STORAGE_CLIENT_SECRET\")\n",
    "}\n",
    "\n",
    "print(\"Variáveis carregadas com sucesso:\", storage_options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12237b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Necessário para escrita no Delta Lake\n",
    "from delta.tables import DeltaTable\n",
    "# Configurar Spark com Delta Lake\n",
    "builder = SparkSession.builder.appName(\"DeltaLakeExample\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.hadoop.fs.azure.account.key.\" + os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\") + \".blob.core.windows.net\", os.getenv(\"AZURE_STORAGE_ACCESS_KEY\"))\n",
    "\n",
    "spark = builder.getOrCreate()\n",
    "\n",
    "def escreve_delta(data, path, mode):\n",
    "    uri = f'az://bronze/delta/delta-operacoes/{path}'\n",
    "    try:\n",
    "        data.write.format(\"delta\") \\\n",
    "            .mode(mode) \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .save(uri)\n",
    "        print(\"Dados escritos com sucesso no Delta Lake!\")\n",
    "    except Exception as e:   print(f\"Erro ao escrever dados no Delta Lake: {e}\")\n",
    "\n",
    "# %%\n",
    "def ler_delta(path):\n",
    "    return DeltaTable.forPath(spark, f'az://bronze/delta/delta-operacoes/{path}')\n",
    "\n",
    "con = duckdb.connect()\n",
    "df = con.sql(\"SELECT * FROM 'C:\\\\Users\\\\Lincoln\\\\source\\\\repos\\\\lakehouse\\\\categories_test.csv'\").to_df()\n",
    "df\n",
    "\n",
    "# %%\n",
    "#con.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a021ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escreve_delta(data, path, mode):\n",
    "    uri = f'az://bronze/delta/delta-operacoes/{path}'\n",
    "    try:\n",
    "        write_deltalake(uri,\n",
    "                         data,\n",
    "                         mode=mode,\n",
    "                         storage_options=storage_options)\n",
    "        print(\"Dados escritos com sucesso no Delta Lake!\")\n",
    "    except DeltaError as e:\n",
    "        print(f\"Erro ao escrever dados no Delta Lake: {e}\")\n",
    "\n",
    "def ler_delta(path):\n",
    "    return DeltaTable(f'az://bronze/delta/delta-operacoes/{path}', storage_options=storage_options)\n",
    "\n",
    "df = con.sql(\"SELECT * FROM 'C:\\\\Users\\\\Lincoln\\\\source\\\\repos\\\\lakehouse\\\\categories_test.csv'\").to_df()\n",
    "df\n",
    "\n",
    "con.close()\n",
    "\n",
    "escreve_delta(df, 'categories', mode='overwrite')\n",
    "\n",
    "dados = ler_delta('categories')\n",
    "dados.to_pandas()\n",
    "\n",
    "dt = ler_delta('categories')\n",
    "#dt.to_pandas()\n",
    "versao = dt.version()\n",
    "print(\"Versão da tabela Delta:\", versao)\n",
    "\n",
    "# %%\n",
    "dt.delete(dt['category_id'] > 4)\n",
    "\n",
    "# %%\n",
    "df_dt = dt.to_pandas()\n",
    "df_filtrado = df_dt[df_dt[\"category_id\"] <= 4]\n",
    "\n",
    "# Sobrescrever a tabela Delta com os dados filtrados\n",
    "df_filtrado\n",
    "#escreve_delta(df_filtrado, 'categories', mode='overwrite')\n",
    "\n",
    "# %%\n",
    "# Usando o objeto dt já carregado com deltalake\n",
    "try:\n",
    "    dt = ler_delta('categories')\n",
    "    print(\"Tabela Delta carregada com sucesso!\")\n",
    "    print(\"Versão da tabela Delta:\", dt.version())\n",
    "    # Exibir algumas informações básicas sobre a tabela\n",
    "    print(\"Caminho da tabela:\", dt.path)\n",
    "    print(\"Número de arquivos:\", len(dt.files()))\n",
    "    print(\"Número de partições:\", len(dt.to_pandas().columns))\n",
    "    print(\"Número de versões:\", dt.history().count())\n",
    "    print(\"Número de colunas:\", len(dt.to_pandas().columns))\n",
    "    print(\"Número de linhas:\", dt.to_pandas().shape[0])\n",
    "    print(\"Colunas:\", dt.to_pandas().columns.tolist())\n",
    "    print(\"Schema:\", dt.schema().json())\n",
    "except DataError as e:\n",
    "    print(f\"Tabela não encontrada ou erro: {str(e)}\")\n",
    "from delta import DeltaTable, write_deltalake, DeltaError, DataError    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9339937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_delta(path):\n",
    "    return DeltaTable(f'az://bronze/delta/delta-operacoes/{path}', storage_options=storage_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414842be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.sql(\"SELECT * FROM 'C:\\\\Users\\\\Lincoln\\\\source\\\\repos\\\\lakehouse\\\\categories_test.csv'\").to_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "escreve_delta(df, 'categories', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd197106",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = ler_delta('categories')\n",
    "dados.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff730d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = ler_delta('categories')\n",
    "#dt.to_pandas()\n",
    "versao = dt.version()\n",
    "print(\"Versão da tabela Delta:\", versao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e89981",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.delete(dt['category_id'] > 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt = dt.to_pandas()\n",
    "df_filtrado = df_dt[df_dt[\"category_id\"] <= 4]\n",
    "\n",
    "# Sobrescrever a tabela Delta com os dados filtrados\n",
    "df_filtrado\n",
    "#escreve_delta(df_filtrado, 'categories', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o objeto dt já carregado com deltalake\n",
    "\n",
    "try:\n",
    "    # Mostrar informações básicas da tabela Delta\n",
    "    print(\"Informações da tabela:\")\n",
    "    print(\"Número de linhas:\", dt.to_pandas().shape[0])\n",
    "    print(\"Colunas:\", dt.to_pandas().columns.tolist())\n",
    "    print(\"Schema:\", dt.schema().json())\n",
    "except DeltaError as e:\n",
    "    print(f\"Tabela não encontrada ou erro: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
